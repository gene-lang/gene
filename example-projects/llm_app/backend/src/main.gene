#!/usr/bin/env gene run

# LLM Chat Backend Server
# Provides REST API endpoints for chat with a local LLM

# Import modules
(import PORT from "config")
(import init_db from "db")
(import init_llm from "llm")
(import chat_id_from_path json_response from "helpers")
(import handle_health handle_chat_new handle_chat handle_chat_stream handle_image_health handle_image_generate handle_image_view handle_oneshot from "handlers")

# ============================================================
# Request Router
# ============================================================
(fn handle_request [req]
  (var path req/.path)
  (var method req/.method)

  (println method path)

  (if (path == "/api/health")
    (handle_health req)
  elif ((path == "/api/chat/new") && (method == "POST"))
    (handle_chat_new req)
  elif ((path .starts_with "/api/chat/") && (path .ends_with "/stream") && (method == "GET"))
    (var conv_id (chat_id_from_path path))
    (handle_chat_stream req conv_id)
  elif ((path .starts_with "/api/chat/") && (method == "POST"))
    (var conv_id (chat_id_from_path path))
    (handle_chat req conv_id)
  elif (path == "/api/image/health")
    (handle_image_health req)
  elif ((path == "/api/image/generate") && (method == "POST"))
    (handle_image_generate req)
  elif ((path == "/api/image/view") && (method == "GET"))
    (handle_image_view req)
  elif ((path == "/api/oneshot") && (method == "POST"))
    (handle_oneshot req)
  else
    (json_response 404 {^error "Not found"})
  )
)

# ============================================================
# Server Startup
# ============================================================
(println "=== LLM Chat Backend ===")
(init_db)
(init_llm)
(println "Starting server on http://localhost:" PORT)
(println "Endpoints:")
(println "  GET  /api/health - Health check")
(println "  POST /api/chat/new - Start conversation")
(println "  POST /api/chat/{id} - Send chat message")
(println "  GET  /api/chat/{id}/stream - SSE chat stream (message query param)")
(println "  GET  /api/image/health - ComfyUI health check")
(println "  POST /api/image/generate - Generate image with ComfyUI")
(println "  GET  /api/image/view - Proxy image from ComfyUI")
(println "  POST /api/oneshot - One-shot LLM with tools (no history)")
(println)

(start_server PORT handle_request)
(run_forever)
